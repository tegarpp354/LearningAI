{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 20:39:33.355238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/macbook/anaconda3/envs/sentiment-analysis-nlp/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Load Model & Tools\n",
    "# -------------------------------\n",
    "with open(\"../models/lstm gru/initial/lstm_model_final.pkl\", \"rb\") as f_lstm:\n",
    "    model_lstm = pickle.load(f_lstm)\n",
    "\n",
    "with open(\"../models/lstm gru/initial/gru_model_final.pkl\", \"rb\") as f_gru:\n",
    "    model_gru = pickle.load(f_gru)\n",
    "\n",
    "with open(\"../models/lstm gru/initial/tokenizer_lstm.pkl\", \"rb\") as f_tok:\n",
    "    tokenizer = pickle.load(f_tok)\n",
    "\n",
    "with open(\"../models/lstm gru/initial/label_encoder_lstm.pkl\", \"rb\") as f_lbl:\n",
    "    label_encoder = pickle.load(f_lbl)\n",
    "\n",
    "max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# STEP 2: Prediction Function\n",
    "# -------------------------------\n",
    "def predict_sentiment(texts, model):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "    preds = model.predict(padded)\n",
    "    classes = np.argmax(preds, axis=1)\n",
    "    labels = label_encoder.inverse_transform(classes)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# STEP 3: Test Tweet\n",
    "# -------------------------------\n",
    "contoh_tweet = [\n",
    "    \"Saya kecewa berat dengan janji politik.\",\n",
    "    \"Debatnya sangat seru dan menarik.\",\n",
    "    \"Biasa saja, tidak terlalu mempengaruhi pilihan saya.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
      "ğŸ“ \"Saya kecewa berat dengan janji politik.\"\n",
      "  ğŸ”µ LSTM: netral\n",
      "  ğŸŸ¢ GRU : netral\n",
      "--------------------------------------------------\n",
      "ğŸ“ \"Debatnya sangat seru dan menarik.\"\n",
      "  ğŸ”µ LSTM: netral\n",
      "  ğŸŸ¢ GRU : netral\n",
      "--------------------------------------------------\n",
      "ğŸ“ \"Biasa saja, tidak terlalu mempengaruhi pilihan saya.\"\n",
      "  ğŸ”µ LSTM: netral\n",
      "  ğŸŸ¢ GRU : positif\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "hasil_lstm = predict_sentiment(contoh_tweet, model_lstm)\n",
    "hasil_gru = predict_sentiment(contoh_tweet, model_gru)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: Tampilkan Hasil\n",
    "# -------------------------------\n",
    "for i, teks in enumerate(contoh_tweet):\n",
    "    print(f\"ğŸ“ \\\"{teks}\\\"\")\n",
    "    print(f\"  ğŸ”µ LSTM: {hasil_lstm[i]}\")\n",
    "    print(f\"  ğŸŸ¢ GRU : {hasil_gru[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/envs/sentiment-analysis-nlp/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load .pkl\n",
    "with open(\"../models/lstm gru/hyperparameter tuning/best_model_lstm.pkl\", \"rb\") as f:\n",
    "    model_lstm = pickle.load(f)\n",
    "\n",
    "with open(\"../models/lstm gru/hyperparameter tuning/best_model_gru.pkl\", \"rb\") as f:\n",
    "    model_gru = pickle.load(f)\n",
    "\n",
    "with open(\"../models/lstm gru/initial/tokenizer_lstm.pkl\", \"rb\") as f_tok:\n",
    "    tokenizer = pickle.load(f_tok)\n",
    "\n",
    "with open(\"../models/lstm gru/initial/label_encoder_lstm.pkl\", \"rb\") as f_lbl:\n",
    "    label_encoder = pickle.load(f_lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi function\n",
    "def predict_sentiment(texts, model, max_len=50):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "    preds = model.predict(padded)\n",
    "    classes = np.argmax(preds, axis=1)\n",
    "    labels = label_encoder.inverse_transform(classes)\n",
    "    return list(zip(texts, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh input\n",
    "contoh = [\n",
    "    \"Saya kecewa dengan kebijakan ekonomi mereka.\",\n",
    "    \"Pemaparan visi misinya sangat jelas dan meyakinkan!\",\n",
    "    \"Saya masih ragu, netral dulu deh.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
      "LSTM ğŸ§  \"Saya kecewa dengan kebijakan ekonomi mereka.\" â†’ netral\n",
      "LSTM ğŸ§  \"Pemaparan visi misinya sangat jelas dan meyakinkan!\" â†’ netral\n",
      "LSTM ğŸ§  \"Saya masih ragu, netral dulu deh.\" â†’ netral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786ms/step\n",
      "GRU ğŸ§  \"Saya kecewa dengan kebijakan ekonomi mereka.\" â†’ netral\n",
      "GRU ğŸ§  \"Pemaparan visi misinya sangat jelas dan meyakinkan!\" â†’ netral\n",
      "GRU ğŸ§  \"Saya masih ragu, netral dulu deh.\" â†’ netral\n"
     ]
    }
   ],
   "source": [
    "# Prediksi\n",
    "for text, pred in zip(contoh, predict_sentiment(contoh, model_lstm)):\n",
    "    print(f\"LSTM ğŸ§  \\\"{pred[0]}\\\" â†’ {pred[1]}\")\n",
    "\n",
    "for text, pred in zip(contoh, predict_sentiment(contoh, model_gru)):\n",
    "    print(f\"GRU ğŸ§  \\\"{pred[0]}\\\" â†’ {pred[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load semua\n",
    "model_lstm = load_model(\"../models/lstm gru/hyperparameter tuning fasttext/lstm_fasttext_model.h5\")\n",
    "model_gru = load_model(\"../models/lstm gru/hyperparameter tuning fasttext/gru_fasttext_model.h5\")\n",
    "\n",
    "with open(\"../models/lstm gru/hyperparameter tuning fasttext/tokenizer_fasttext.pkl\", \"rb\") as f_tok:\n",
    "    tokenizer = pickle.load(f_tok)\n",
    "\n",
    "with open(\"../models/lstm gru/hyperparameter tuning fasttext/label_encoder_fasttext.pkl\", \"rb\") as f_lbl:\n",
    "    label_encoder = pickle.load(f_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi fungsi\n",
    "def predict_sentiment(texts, model, max_len=50):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "    preds = model.predict(padded)\n",
    "    classes = np.argmax(preds, axis=1)\n",
    "    labels = label_encoder.inverse_transform(classes)\n",
    "    return list(zip(texts, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh input\n",
    "sample = [\n",
    "    \"Saya sangat kagum dengan pidatonya.\",\n",
    "    \"Bingung mau pilih siapa, semua biasa saja.\",\n",
    "    \"Kebijakan ini tidak masuk akal sama sekali.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LSTM:\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x168996950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x168996950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "\"Saya sangat kagum dengan pidatonya.\" â†’ netral\n",
      "\"Bingung mau pilih siapa, semua biasa saja.\" â†’ negatif\n",
      "\"Kebijakan ini tidak masuk akal sama sekali.\" â†’ netral\n",
      "\n",
      "ğŸ§  GRU:\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x168996b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x168996b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "\"Saya sangat kagum dengan pidatonya.\" â†’ positif\n",
      "\"Bingung mau pilih siapa, semua biasa saja.\" â†’ negatif\n",
      "\"Kebijakan ini tidak masuk akal sama sekali.\" â†’ netral\n"
     ]
    }
   ],
   "source": [
    "# Output LSTM vs GRU\n",
    "print(\"ğŸ§  LSTM:\")\n",
    "for text, label in predict_sentiment(sample, model_lstm):\n",
    "    print(f\"\\\"{text}\\\" â†’ {label}\")\n",
    "\n",
    "print(\"\\nğŸ§  GRU:\")\n",
    "for text, label in predict_sentiment(sample, model_gru):\n",
    "    print(f\"\\\"{text}\\\" â†’ {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-analysis-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
